{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[論文:Generative Adversarial Nets](https://github.com/annali/GANs-Note/blob/master/papers/Generative%20Adversarial%20Nets.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- G（Generator）：模擬數據分佈，目的是最大化D犯錯的概率\n",
    "- D（Discriminator）：估計一個樣本來自訓練集的概率，目的是最小化D犯錯的概率\n",
    "- 最後達到1/2的平衡狀態"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- G和D由multilayer perceptrons定義\n",
    "- 系統可以使用backpropagation訓練\n",
    "- 訓練或產生樣本的時候不需要Markov chains或者unrolled approximate inference networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 本論文實驗通過對生成的樣品進行定性和定量評估來證明該框架的潛力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most striking successes in deep learning have involved discriminative models\n",
    "- These striking successes have primarily been based on the backpropagation and dropout algorithms, using piecewise linear units which have a particularly well-behaved gradient\n",
    "- In the proposed adversarial nets framework, the generative model is pitted against an adversary:a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution.\n",
    "- This framework can yield specific training algorithms for many kinds of model and optimization algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RBMs\n",
    "- DBMs\n",
    "- DBNs\n",
    "- auto-encoding variational Bayes : training a generative machine\n",
    "- stochastic backpropagation : training a generative machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adversarial modeling framework :  straightforward to apply when the models are both multilayer perceptrons\n",
    "- We train D to maximize the probability of assigning the correct label to both training examples and samples from G. \n",
    "- We simultaneously train G to minimize log(1 − D(G(z)))\n",
    "- D and G play the following two-player minimax game with value function V (G, D):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![公式](images/01.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- G的目的：D(G(z))是D網絡判斷G生成的資訊是否真實的概率，G應該希望自己生成的資訊\"越接近真實越好\"。也就是說，G希望D(G(z))盡可能得大，這時V(D, G)會變小。因此公式的最前面的記號是min_G。\n",
    "- D的目的：D的能力越強，D(x)應該越大，D(G(z))應該越小，這時V(D,G)會變大。因此公式對於D來說是求最大(max_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Early in learning, when G is poor, D can reject samples with high confidence because they are clearly different from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一堆公式，暫時先略過"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset：MNIST，Toronto Face，CIFAR-10\n",
    "- G(Generator)：RELU激活函數和sigmoid激活函數\n",
    "- D(Discriminator)：maxout激活函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and disadvantages\n",
    "#### 優勢\n",
    "- 不需要Markov chains，僅用反向傳播來獲得梯度，學習間無需推理，且模型中可融入多種function\n",
    "\n",
    "#### 劣勢\n",
    "- 主要為pg(x) 的隱式表示，且訓練期間，D和G必須很好地同步（尤其，不更新D時G不必過度訓練，為避免\"Helvetica情景\"。否則x值相同時G丟失過多z值以至於模型pdata多樣性不足）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions and future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通過添加c作為G和D的輸入，得到條件生成模型p(x|c)。\n",
    "- 給定x，通過訓練，學習近似推理，預測z。這和wake-sleep算法訓練的推理網絡相似，但是有一個優點：推理網絡用於在G結束訓練之後的固定的G。\n",
    "- 可以通過訓練共享參數的條件模型族來近似地模擬所有條件p（xS |x̸S），其中S是x的索引的子集。實質上，可以使用對抗網來實現確定性MP-DBM的隨機擴展\n",
    "- 半監督學習：當有限的標記數據可用時，從D或者推理網絡的特徵可以提高分類器的性能。\n",
    "- 效率提高：通過劃分協調G和D的方法或者在訓練期間確定更好的樣本z的分佈，可以加快訓練速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 心得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gan的重點在於G與D的角色扮演定位\n",
    "- 一個很有趣的Network，若可以依據vector生成各種不同的形式的output(影像，句子，音樂....)，科幻電影的情節在不久的將來是非常有機會在現實生活中看得到的，不過這是個很值得探討的問題，若機器都可以生成這樣的資訊，那我們還能做些什麼？\n",
    "- 梯度下降應該也會是訓練的時候遇到的問題點，需更花心思來調教(when G is poor, D can reject samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
