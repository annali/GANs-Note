{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 關於Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 生成模型的兩種方法：\n",
    "<br>\n",
    "1.概率估計：就是說在不了解事件概率分佈的情況下，先假設隨機分佈，然後通過數據觀測來確定真正的概率密度是怎樣的。\n",
    "<br>\n",
    "2.樣本生成：就是手上有一把訓練樣本數據，通過訓練後的模型來生成類似的“樣本”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 為什麼需要生成模型：\n",
    "<br>\n",
    "1.可以很好的檢測處理高維數據和複雜概率分佈的能力\n",
    "<br>\n",
    "2.為未來的規劃或模擬型強化學習做好理論準備\n",
    "<br>\n",
    "3.面臨缺乏數據的情況，可以通過生成模型來補足。\n",
    "<br>\n",
    "4.可以輸出Multi-modal結果（Multi-modal outouts）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gan面臨的問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不收斂\n",
    "<br>\n",
    "現在GAN 面臨的最大問題就是不穩定，很多情況下都無法收斂（non-convergence）。\n",
    "<br>\n",
    "原因是我們使用的優化方法很容易只找到一個局部最優點，而不是全局最優點。或者，有些算法根本就沒法收斂。\n",
    "<br>\n",
    "模式崩潰（mode collapse）就是一種無法收斂的情況。\n",
    "<br>\n",
    "在最理想的狀態下，對抗的結果是，G生成足以以假亂真的圖片G(z)，D難以判定他究竟是不是真的，因此此時D(G(z)) = 0.5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 無法科學的評估\n",
    "<br>\n",
    "對於整個生成模型領域來說，另一個問題是沒法科學地進行評估。\n",
    "<br>\n",
    "例如：拿一堆圖片生成另一堆圖片，可是這兩批圖片其實可能看起來天差地別。人可以判斷出生成的小狗照片對不對，機器卻沒法量化這個標準。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 離散輸出\n",
    "<br>\n",
    "如果我們的G 想要生成離散值，就會遇到一個數學問題：無法微分（differentiate）。\n",
    "當然，這個問題其實在ANN 時代就被討論過，並有很多解決方案，比如，Williams(1992) 經典的REINFORCE、Jang et al.(2016) 的Gumbel-softmax、以及最簡單粗暴地用連續數值做訓練，最後框個範圍，再輸出離散值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 強化學習的連接\n",
    "<br>\n",
    "GAN 在給強化學習做加持的時候，也有點問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GAN是一種用可以估測複雜目標函數的生成模型\n",
    "- GAN 可以估測很多目標函數，包括最大似然（Maximum likelihood）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在最理想的狀態下，對抗的結果是，G生成足以以假亂真的圖片G(z)，D難以判定他究竟是不是真的，因此此時D(G(z)) = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
